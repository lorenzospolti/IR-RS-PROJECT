{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62f8007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff6a6d",
   "metadata": {},
   "source": [
    "## Download the Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8b30745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1346  100  1346    0     0   4063      0 --:--:-- --:--:-- --:--:--  4078\n",
      "100 71.5M  100 71.5M    0     0  10.3M      0  0:00:06  0:00:06 --:--:-- 10.6M     0  0:00:07  0:00:02  0:00:05 12.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1352  100  1352    0     0   4387      0 --:--:-- --:--:-- --:--:--  4389\n",
      "100 1315M  100 1315M    0     0  11.3M      0  0:01:56  0:01:56 --:--:-- 12.0M    0  6809k      0  0:03:17  0:00:06  0:03:11 8541k117k      0  0:02:45  0:00:08  0:02:37 11.0M0:02:00  0:00:51  0:01:09 11.8M  0  0:01:58  0:01:04  0:00:54 12.3M11.1M      0  0:01:57  0:01:08  0:00:49 12.0M      0  0:01:56  0:01:31  0:00:25 10.3M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1344  100  1344    0     0   4312      0 --:--:-- --:--:-- --:--:--  4307\n",
      "100 71.8M  100 71.8M    0     0  8246k      0  0:00:08  0:00:08 --:--:-- 11.8M\n",
      "\n",
      "===== train.json =====\n",
      "Preview of first 500 characters:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"query_id\": \"train_1\",\n",
      "        \"question\": \"Who is the author of the book, \\\"Horrors of Slavery, or the American Turf in Tripoli\\\"?\",\n",
      "        \"answer\": \"WILLIAM RAY\",\n",
      "        \"org_answer\": \"WILLIAM RAY\",\n",
      "        \"para_id\": \"New_Hampshire_18070804_1\",\n",
      "        \"context\": \"Aiscellaneous Repository. From the Albany Register, WAR, OR A PROSPECT OF IT, From recent instances of British Outrage. BY: WILLIAM RAY, Author of the contemplated publication, entitled, \\u201cHorrors of Slavery, \n",
      "\n",
      "Loaded 439302 items (list).\n",
      "Dictionary keys: ['query_id', 'question', 'answer', 'org_answer', 'para_id', 'context', 'raw_ocr', 'publication_date', 'trans_que', 'trans_ans', 'url']\n",
      "{\n",
      "  \"query_id\": \"train_1\",\n",
      "  \"question\": \"Who is the author of the book, \\\"Horrors of Slavery, or the American Turf in Tripoli\\\"?\",\n",
      "  \"answer\": \"WILLIAM RAY\",\n",
      "  \"org_answer\": \"WILLIAM RAY\",\n",
      "  \"para_id\": \"New_Hampshire_18070804_1\",\n",
      "  \"context\": \"Aiscellaneous Repository. From the Albany Register, WAR, OR A PROSPECT OF IT, From recent instances of British Outrage. BY: WILLIAM RAY, Author of the contemplated publication, entitled, \\u201cHorrors of Slavery, or the American Turf in Tripoli,\\u201d VOTARIES of Freedom, arm! The British Lion roars! Legions of Valor, take th\\u2019 alarm\\u2014; Rash, ru\n",
      "\n",
      "===== validation.json =====\n",
      "Preview of first 500 characters:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"query_id\": \"val_1\",\n",
      "        \"question\": \"How much of the crew would Gerry want to shore up in a gale of wind?\",\n",
      "        \"answer\": \"half\",\n",
      "        \"org_answer\": \"half\",\n",
      "        \"para_id\": \"Maine_18100326_13\",\n",
      "        \"context\": \"But my lads, it was right to put in federal officers last year, and the crew knew it; they saw what was brewing well enough, and by the soul of me, if the federal men hadn't done what they did, Old Davy Jones would have had his clutches into our quarters \n",
      "\n",
      "Loaded 24111 items (list).\n",
      "Dictionary keys: ['query_id', 'question', 'answer', 'org_answer', 'para_id', 'context', 'raw_ocr', 'publication_date', 'trans_que', 'trans_ans', 'url']\n",
      "{\n",
      "  \"query_id\": \"val_1\",\n",
      "  \"question\": \"How much of the crew would Gerry want to shore up in a gale of wind?\",\n",
      "  \"answer\": \"half\",\n",
      "  \"org_answer\": \"half\",\n",
      "  \"para_id\": \"Maine_18100326_13\",\n",
      "  \"context\": \"But my lads, it was right to put in federal officers last year, and the crew knew it; they saw what was brewing well enough, and by the soul of me, if the federal men hadn't done what they did, Old Davy Jones would have had his clutches into our quarters long ago. And now who d'ye think they want to put in instead of our present Commander C. GORE, and the Chief Mate COBB, an old weather-beaten \n",
      "\n",
      "===== test.json =====\n",
      "Preview of first 500 characters:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"query_id\": \"test_1\",\n",
      "        \"question\": \"How many lots did Thomas Peirce have?\",\n",
      "        \"answer\": \"183\",\n",
      "        \"org_answer\": \"183\",\n",
      "        \"para_id\": \"New_Hampshire_18030125_16\",\n",
      "        \"context\": \"Axivil Roberts, part of lot 180 108 60 Capt. George Walker, 181 140 35 George Townson, 183 48 19 Samuel Snell, 184 36 9 Samuel Waterhouse, 185 24 6 John Parker, 186 36 10 John Davis, 187 45 20 John Cross, 188 15 4 Benjamin Cross, 189 50 13 Widow Gilman, 209 21 8 George Peirce, 2\n",
      "\n",
      "Loaded 24084 items (list).\n",
      "Dictionary keys: ['query_id', 'question', 'answer', 'org_answer', 'para_id', 'context', 'raw_ocr', 'publication_date', 'trans_que', 'trans_ans', 'url']\n",
      "{\n",
      "  \"query_id\": \"test_1\",\n",
      "  \"question\": \"How many lots did Thomas Peirce have?\",\n",
      "  \"answer\": \"183\",\n",
      "  \"org_answer\": \"183\",\n",
      "  \"para_id\": \"New_Hampshire_18030125_16\",\n",
      "  \"context\": \"Axivil Roberts, part of lot 180 108 60 Capt. George Walker, 181 140 35 George Townson, 183 48 19 Samuel Snell, 184 36 9 Samuel Waterhouse, 185 24 6 John Parker, 186 36 10 John Davis, 187 45 20 John Cross, 188 15 4 Benjamin Cross, 189 50 13 Widow Gilman, 209 21 8 George Peirce, 209 200 75 Thomas Peirce, 220 185 71 SIXTH RANGE: Col. Henry Sherburne, 241 552 150 Nathaniel Roberts, 249 30 8 Jonathan Patridge, 252 60 18 Jo\n"
     ]
    }
   ],
   "source": [
    "!curl -L \"https://huggingface.co/datasets/Bhawna/ChroniclingAmericaQA/resolve/main/test.json?download=true\" -o test.json\n",
    "!curl -L \"https://huggingface.co/datasets/Bhawna/ChroniclingAmericaQA/resolve/main/train.json?download=true\" -o train.json\n",
    "!curl -L \"https://huggingface.co/datasets/Bhawna/ChroniclingAmericaQA/resolve/main/dev.json?download=true\" -o validation.json\n",
    "\n",
    "import json\n",
    "\n",
    "files = [\"train.json\", \"validation.json\", \"test.json\"]\n",
    "\n",
    "for path in files:\n",
    "    print(f\"\\n===== {path} =====\")\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            # Read a few hundred characters to see what kind of JSON it is\n",
    "            head = f.read(500)\n",
    "            print(\"Preview of first 500 characters:\\n\")\n",
    "            print(head[:500])\n",
    "        # Try to load only part of the file\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, list):\n",
    "            print(f\"\\nLoaded {len(data)} items (list).\")\n",
    "            print(\"Dictionary keys:\", list(data[0].keys()))\n",
    "            print(json.dumps(data[0], indent=2)[:600])\n",
    "        elif isinstance(data, dict):\n",
    "            print(\"\\nTop-level is a dictionary. Keys:\", list(data.keys()))\n",
    "            for k, v in data.items():\n",
    "                if isinstance(v, list):\n",
    "                    print(f\"Key '{k}' contains a list of {len(v)} items.\")\n",
    "                    if v:\n",
    "                        print(\"First item keys:\", list(v[0].keys()))\n",
    "                        print(json.dumps(v[0], indent=2)[:600])\n",
    "                        break\n",
    "        else:\n",
    "            print(f\"Unexpected top-level type: {type(data)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not parse {path} as JSON: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402d4be",
   "metadata": {},
   "source": [
    "## Create the Document Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29504f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 439302 records from train.json\n",
      "Loaded 24111 records from validation.json\n",
      "Loaded 24084 records from test.json\n",
      "Wrote 131921 records to document_collection.json\n",
      "[\n",
      "  {\n",
      "    \"para_id\": \"New_Hampshire_18070804_1\",\n",
      "    \"context\": \"Aiscellaneous Repository. From the Albany Register, WAR, OR A PROSPECT OF IT, From recent instances of British Outrage. BY: WILLIAM RAY, Author of the contemplated publication, entitled, \\u201cHorrors of Slavery, or the American Turf in Tripoli,\\u201d VOTARIES of Freedom, arm! The British Lion roars! Legions of Valor, take th\\u2019 alarm\\u2014; Rash, rush to guard our shores! Behold the horrid deed\\u2014 Your brethren gasping lie! Beneath a tyrant\\u2019s hand they bleed\\u2014 They groan\\u2014they faint\\u2014they die. Veterans of seventy-six, Awake the slumbering sword;\\u2014 Hearts of your murderous foes transfix\\u2014 'Tis vengeance gives the word. Remember Lexington, And Bunker\\u2019s tragic hill; \\u201cThe same who spilt your blood thereon, Your blood again would spill. Ye who have seen your wives, Your children, and your fires, Too British ruffians yield their lives, And roast in savage fires;\\u2014 Our cities lost in flames,\\u2014 Your mothers captive led; Rise and avenge their injured names, Ye kindred of the dead. But not Revenge alone, Should urge you to the field; Let Duty lead you firmly on, And justice be your shield. Sure as we fail to join And crush our impious foes, War, fire and sword, and death combine, And woes succeed to woes.\",\n",
      "    \"raw_ocr\": \"fAiscellancous Bepogitory.\\n. dvom the Albany Regifier,\\n. . WAR,OR A PROSPECT OF IT,\\nFrom recent inflances of Britifp Oulrage.\\n BY: WILLIAM RAY:\\nHAuthsr of the tontemplated publication, entitled,\\n\\u00ab Horrors of Slavery,or the American Turg\\nin Tripoli,\\u201d\\nVOT\\u2019RIES of Freedom, arm!\\n The British Lion roars !\\n Legions of Valor, take th\\u2019 alarm\\u2014 ;\\nRash, rush to guard our shores ! -\\n- Behold the horrid deed\\u2014 v\\n. Your brethren gasping lie!\\n Beneath a tyrant\\u2019s hand they bleed\\u2014 -\\nThey groan--they faint\\u2014they die.\\n _Vet\\u2019rans of seventy-six, i\\n. Awake the flumb\\u2019ring sword ;\\u2014 = *.\\n- Hearts of your murd\\u2019rous foes transfix\\u2014\\n*Tis vengeance gives the word.\\n Remember Lexington,\\nAnd Bunker\\u2019s tragic hill;\\n\\u201cThe fame who {pilt your blnod thereon,\\n- Your blnod again would spill,\\nYe who have fe\\u00e9n your wives,\\nYour childrea, and your fires,\\n7\\u2019oo British ruffians\\u2019 yield their lives, .\\n Apd roast in savage fires;\\u2014\\nQer cities loft in lames,\\u2014\\nYour mothers captive led;\\nRife and avenge their injur'd names, -\\nYe kindred of the dead: .\\n But not Revenge alone,\\nShould \\u2018grge you to the field ;\\n. Let Duty lead you firmly on, :\\n. Aond jultice be your shield.\\n Sure as we fail to join\\n\\u00a2 And eruih our impeous foes,\\n\\u00bb Woar, fire and sword, and dcath combie,\\n- And woes succeed to woes.\",\n",
      "    \"publication_date\": \"1807-08-04\"\n",
      "  },\n",
      "  {\n",
      "    \"para_id\": \"New_Hampshire_18070804_4\",\n",
      "    \"context\": \"Surely he above the rest of his fellow mortals, partakes of heaven here below, of bliss which none but the virtuous ever claim. \\u00a5 Obituary B In France, Gen. de Rosemberg, aged 83, formerly Marshal of France, Grand Officer of the Legion of Honor, and commander of the French troops in the United States during the Revolutionary war. \\u00a5 In Washington, Hon. Uriah Tracy, Esq. Senator of the United States from the State of Connecticut, aged 54\\u2014his pall was supported by the heads of department and officers of government\\u2014he had been sick at Washington since March last. In Baltimore, during the week ending the 18th ult. 15 adults and 23 children. In Philadelphia, during the week ending 18th ult.\\u201424 adults and 40 children. In New-York, during the week ending 18th ult, 2 men, 6 women, 10 boys and 7 girls. At Newark, (N. J.) the Rev. Dr. Alexander Macauley, aged 73. At Danvers, Dr. Amos Putnam, aged 83. At Andover, Mrs. Susanna Symmes, relict of the late Rev. Dr. Wm. Symmes, aged 79. At Salem, (Mass) Widow Margaret Swaffey, aged 100 years and 6 months. At Newburyport, Mr. Samuel Dexter, aged 36, only son of the late Lord T. Dexter. At Brunswick, Rev. Joseph McKean, D. D, late president of Bowdoin college. At Lancaster, Mr. Henry Haskell, aged 73, a Lt. Col. in the revolutionary army. At Chesterfield, Mrs. Louisa Parsons, wife of Benjamin Parsons, Esq. aged 39.\",\n",
      "    \"raw_ocr\": \"Surely he a\\nbove the rest of his fellow mortals, partakes\\nof heaven hcre below, of bliss which nene\\nbut the virtuous ever claim.\\n \\u00a5 OvoioDlEDoitry B\\n In France, Gen.de Rosbambesu, aged 8,\\nfarmerly s Marthall of France, Grand Ofa\\ncer of the Legion of Henor,and commander\\nof the Freach troops in the United States\\nduring the Revolutienary war. \\u00a5\\n In Wathington, Hon. Uriab Tracey, Esq.\\nYenator of the United States from-the State\\nof Connecticut, aged s4~\\u2014his pall was sup\\nported by the, heads of department and\\nofficers of goverament\\u2014he had been sick at\\nWashington since March lag.\\n In Baltumore, during the week ending the\\n18th uvit. 15 adults and 23 childiren.\\n In Philadelphia, during the week ending\\n18th u1t.~\\u201424 adults and 40 children.\\n ~ln New-York, during the week ending\\n18th nlt, 2 men, 6 womcen, 10 boys and 7\\ngirls, . : ' \\u00a2 \\u00a5 oo\\nAt Newark, (N. ].) the Rev, Dr. Alexander\\nMacauwgrther, aged 73. ; (\\n. At Daovers, Dt. Amos Putnam,aged 83.\\n At Andover, Mrs. Susanna Symmes, relict\\nof the late Rev. Dr. Wm. Symmes, aged 79.\\n At Salem, (Mass) Widow Margaret Swafey,\\naged 100 yearsand 6 months.\\n. At Newburyport, Mr.\\\" Samuel Dexter, aged\\n- 36, only son of the late Lord T. Dexter.\\n o At Bruafwick, Rev. Fo/eph McKean, D. D,\\nJate president of Bowdoin college.\\n At Lancaster, Mr. Henry Hajkell, aged 73,\\na Lt, Col. in the revolutionary army.\\n At Cheflterfield, Mrs Louisa Parsons, wifoy\\n-of Benjamin Parlons, Efq.aged 39. i\\n-\",\n",
      "    \"publication_date\": \"1807-08-04\"\n",
      "  },\n",
      "  {\n",
      "    \"para_id\": \"New_Hampshire_18070804_5\",\n",
      "    \"context\": \"At Westmoreland, Mrs. Sally Lincoln, wife of Mr. Spencer L. aged 28.  At Henrico, Mrs. Polly Adams, consort On Saturday, the 11th ult. Mr. Joseph Meyer, of Hampstead, was found dead in the road, (his horse standing by him) when oy e g e SMITH & RUST Pocket Book Lost.  \\\"LOST last Wednesday between 7 and 8 o\\u2019clock in the afternoon, either in the Globe Tavern at the Plains, or on the road leading from thence to Portsmouth, a new Red Morocco Pocket Book ; containing some Money, Notes of hand payable to the Subscriber, also, New Hampshire Fire and Marine Certificates, and other papers valuable to none but to the owner\\u2014Whoever shall find said Pocket Book, and re- turn it with its contents, with or without the money shall be handsomely rewarded, and the thanks of their humble servant EDWARD. PARRY.  TO BE LET, That Fireproof Store lately improved by Mr. Benjamin Swett, which must be allowed to be the best stand for business, either for English or West- India Goods in this town\\u2014Inquire of EDWARD PARRY, Who has a large assortment of the fashionable GOODS, for sale cheap for cash or short credit. July 28.  FOR SALE, A NEW GONDOLA, built of the best materials, and by an experienced workman, forty feet cor- ner piece,\\u2014For further particulars enquire of MICHAEL WIGGIN. Newmarket, July 27th, 1807 2. CHAISE.\",\n",
      "    \"raw_ocr\": \"At Weltmoreland, Mrs. Sally Liacoln, wife\\n~of Mr,Spencer L.aged 28. 77\\niAt Hennikee, Mrs. Polly Adams, consort\\n00 Baturday, the lith vit. Mr. Jo/iph\\nNeyer, of Hampftead, was found dead in the\\nroud. (his Borfe Randing by him) sbens oy\\ne g e\\nSMR R Y e sT R\\nPocket Book Loft.\\n i\\u201c OSS i'laft Wednesday between 7-\\nJM_4 and 8 o\\u2019clock in the afternoon,\\neither in the Globe Tavern at the\\nPlains, or cn the road leading from\\nthence to Portsmouth, a new j\\nRed Morscco Pocket Book ;\\ncontaining some Money, Notes of hand\\npayable to the Subscriber. alfs,\\nNewhampfhire Fire and Marine\\nCertificates, and other papers valuable\\nto no ore but to the owner\\u2014Whoev\\ner shall find said Pocket Book, and re-,\\nturn it wich its contents, with or with.\\n out the money {hall be hand{omely re\\nwarded, aand the thanks of their hum.\\nble servant EDWARD. PARRY.\\n 10 BE LET,\\nThat Fire proof Store lately improv\\ned by Mr. Benjamin Swett, which\\nmust be allowed to be the best stand\\nfor business, either for English or Welt-\\nIndia Goods in this town\\u2014llinquire\\nof \\\" EDWARD PARRY,\\nWho has a large assortment fieth\\nfathionable GOQODS, for {ale cheap\\nfor cath or short credit. Fuly 28.\\n FOR SALE,\\nANEW GUNDALO,\\nbuilt of the belt materials, and by an\\nexperienced workman, forty feet cor\\nner piece,\\u2014For further particulars\\nenquire of\\n\\\" MICHAEL WIGGIN.\\nNewmarket, July 27th, 1807\\n2 .\\nCHAISE.\\n\",\n",
      "    \"publication_date\": \"1807-08-04\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "inputs = [\"train.json\", \"validation.json\", \"test.json\"]\n",
    "output = \"document_collection.json\"\n",
    "\n",
    "def load_list_or_empty(path):\n",
    "    if not os.path.exists(path) or os.path.getsize(path) == 0:\n",
    "        print(f\"Skipping {path} because it is missing or empty\")\n",
    "        return []\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, list):\n",
    "            return data\n",
    "        print(f\"Skipping {path} because it is not a list at the top level\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Skipping {path} because it is not valid JSON\")\n",
    "        return []\n",
    "\n",
    "def project(recs):\n",
    "    out = []\n",
    "    for r in recs:\n",
    "        out.append({\n",
    "            \"para_id\": r.get(\"para_id\", \"\"),\n",
    "            \"context\": r.get(\"context\", \"\"),\n",
    "            \"raw_ocr\": r.get(\"raw_ocr\", \"\"),\n",
    "            \"publication_date\": r.get(\"publication_date\", \"\")\n",
    "        })\n",
    "    return out\n",
    "\n",
    "all_recs = []\n",
    "for p in inputs:\n",
    "    recs = load_list_or_empty(p)\n",
    "    print(f\"Loaded {len(recs)} records from {p}\")\n",
    "    all_recs.extend(project(recs))\n",
    "\n",
    "# deduplicate by para_id keeping the first one seen\n",
    "uniq = {}\n",
    "for rec in all_recs:\n",
    "    pid = rec.get(\"para_id\", \"\")\n",
    "    if pid and pid not in uniq:\n",
    "        uniq[pid] = rec\n",
    "\n",
    "result = list(uniq.values())\n",
    "\n",
    "with open(output, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Wrote {len(result)} records to {output}\")\n",
    "print(json.dumps(result[:3], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84161a1d",
   "metadata": {},
   "source": [
    "## Create the Test Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b60b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 entries to test_queries.json\n",
      "[\n",
      "  {\n",
      "    \"query_id\": \"test_1\",\n",
      "    \"question\": \"How many lots did Thomas Peirce have\"\n",
      "  },\n",
      "  {\n",
      "    \"query_id\": \"test_10\",\n",
      "    \"question\": \"Who gave Hamilton the substance of what he had proposed on the part of General Hamilton\"\n",
      "  },\n",
      "  {\n",
      "    \"query_id\": \"test_100\",\n",
      "    \"question\": \"Who informs his FRIENDS and the PUBLIC that he has taken that justly celebrated INN in this city\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "input_file = \"test.json\"\n",
    "output_file = \"test_queries.json\"\n",
    "\n",
    "# Load the data\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "def clean_question(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", \" \", text)  # remove punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "# Extract and clean\n",
    "queries = [\n",
    "    {\n",
    "        \"query_id\": item.get(\"query_id\", \"\"),\n",
    "        \"question\": clean_question(item.get(\"question\", \"\")),\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# Sort by query_id (assuming numeric)\n",
    "queries = sorted(queries, key=lambda x: int(x[\"query_id\"]) if str(x[\"query_id\"]).isdigit() else x[\"query_id\"])\n",
    "\n",
    "# Keep only the first 10,000\n",
    "queries = queries[:10000]\n",
    "\n",
    "# Save new JSON\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(queries, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(queries)} entries to {output_file}\")\n",
    "print(json.dumps(queries[:3], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017ea071",
   "metadata": {},
   "source": [
    "## Create the QRels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ae4e794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 24084 entries to test_qrels.json\n",
      "Saved 24084 entries to test_query_answers.json\n",
      "Sample qrels entry: {'query_id': 'test_1', 'iteration': 0, 'para_id': 'New_Hampshire_18030125_16', 'relevance': 1}\n",
      "Sample query_answers entry: {'query_id': 'test_1', 'iteration': 0, 'para_id': 'New_Hampshire_18030125_16', 'relevance': 1, 'answer': '183', 'org_answer': '183'}\n"
     ]
    }
   ],
   "source": [
    "input_file = \"test.json\"\n",
    "qrels_file = \"test_qrels.json\"\n",
    "answers_file = \"test_query_answers.json\"\n",
    "\n",
    "# Load the data\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Build the qrels file: query_id, iteration=0, para_id, relevance=1\n",
    "qrels = [\n",
    "    {\n",
    "        \"query_id\": item.get(\"query_id\", \"\"),\n",
    "        \"iteration\": 0,\n",
    "        \"para_id\": item.get(\"para_id\", \"\"),\n",
    "        \"relevance\": 1\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# Build the query_answers file: same plus answer and org_answer\n",
    "query_answers = [\n",
    "    {\n",
    "        \"query_id\": item.get(\"query_id\", \"\"),\n",
    "        \"iteration\": 0,\n",
    "        \"para_id\": item.get(\"para_id\", \"\"),\n",
    "        \"relevance\": 1,\n",
    "        \"answer\": item.get(\"answer\", \"\"),\n",
    "        \"org_answer\": item.get(\"org_answer\", \"\")\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# Save both files\n",
    "with open(qrels_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qrels, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(answers_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(query_answers, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved {len(qrels)} entries to {qrels_file}\")\n",
    "print(f\"Saved {len(query_answers)} entries to {answers_file}\")\n",
    "print(\"Sample qrels entry:\", qrels[0])\n",
    "print(\"Sample query_answers entry:\", query_answers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67f754",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4632b280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0d/x5py94gd6g3dg3p7jns5sv4r0000gn/T/ipykernel_1456/482221578.py:4: DeprecationWarning: Call to deprecated function (or staticmethod) started. (use pt.java.started() instead) -- Deprecated since version 0.11.0.\n",
      "  if not pt.started():\n",
      "Java started and loaded: pyterrier.java.colab, pyterrier.java, pyterrier.java.24, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "/var/folders/0d/x5py94gd6g3dg3p7jns5sv4r0000gn/T/ipykernel_1456/482221578.py:5: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "import pandas as pd\n",
    "import re \n",
    "if not pt.started():\n",
    "    pt.init() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d59caa6",
   "metadata": {},
   "source": [
    "We turn everything into a pandas dataframe for easier manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bb0f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries DataFrame:\n",
      "        query_id                                           question\n",
      "0         test_1               How many lots did Thomas Peirce have\n",
      "1        test_10  Who gave Hamilton the substance of what he had...\n",
      "2       test_100  Who informs his FRIENDS and the PUBLIC that he...\n",
      "3      test_1000  Who was the Secretary of the Treasury of the U...\n",
      "4     test_10000     Who made a speech in front of the Brooks House\n",
      "...          ...                                                ...\n",
      "9995  test_18995  How many rounds does McFadden need to fight Jo...\n",
      "9996  test_18996  What company has a receiver appointed at Lawre...\n",
      "9997  test_18997     How much did the price go on September 13 1900\n",
      "9998  test_18998  What state is Salt Lake City Territory located in\n",
      "9999  test_18999  What party did Truro Crane and John P Meakin b...\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "Qrels DataFrame:\n",
      "         query_id  iteration                    para_id  relevance\n",
      "0          test_1          0  New_Hampshire_18030125_16          1\n",
      "1          test_2          0       Virginia_18080322_16          1\n",
      "2          test_3          0  New_Hampshire_18030125_16          1\n",
      "3          test_4          0  New_Hampshire_18030125_16          1\n",
      "4          test_5          0  New_Hampshire_18030125_16          1\n",
      "...           ...        ...                        ...        ...\n",
      "24079  test_24080          0           Iowa_19180904_14          1\n",
      "24080  test_24081          0            Utah_19200914_8          1\n",
      "24081  test_24082          0       Minnesota_19200121_2          1\n",
      "24082  test_24083          0        Nebraska_19170612_5          1\n",
      "24083  test_24084          0      Tennessee_19190220_12          1\n",
      "\n",
      "[24084 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#  Convert the list of dictionaries into a pandas DataFrame\n",
    "queries_df = pd.DataFrame(queries)\n",
    "qrels_df = pd.DataFrame(qrels)\n",
    "\n",
    "# Filter out rows where the 'question' is now empty\n",
    "queries_df = queries_df[queries_df['question'].str.len() > 0]\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Queries DataFrame:\")\n",
    "print(queries_df)\n",
    "print(\"Qrels DataFrame:\")\n",
    "print(qrels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c65988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset created with 131921 documents.\n",
      "                      docno                                            context\n",
      "0  New_Hampshire_18070804_1  Aiscellaneous Repository. From the Albany Regi...\n",
      "1  New_Hampshire_18070804_4  Surely he above the rest of his fellow mortals...\n",
      "2  New_Hampshire_18070804_5  At Westmoreland, Mrs. Sally Lincoln, wife of M...\n",
      "3  New_Hampshire_18070804_8  Upon the correction of this remedy the stomach...\n",
      "4  New_Hampshire_18070804_9  Also FOR SALE AS ABOVE, NEW GOODS, STEPHEN HAR...\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the JSON file\n",
    "input_file = \"document_collection.json\"\n",
    "\n",
    "if os.path.exists(input_file):\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # 2. Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # 3. Select ONLY 'para_id' and 'context'\n",
    "    df = df[[\"para_id\", \"context\"]]\n",
    "\n",
    "    # 4. RENAME columns to match what PyTerrier needs\n",
    "    df = df.rename(columns={\n",
    "        \"para_id\": \"docno\"\n",
    "    })\n",
    "\n",
    "    # 5. Type Safety (Make sure they are strings)\n",
    "    df[\"docno\"] = df[\"docno\"].astype(str)\n",
    "    df[\"context\"] = df[\"context\"].astype(str)\n",
    "\n",
    "    print(f\"✅ Dataset created with {len(df)} documents.\")\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff852d",
   "metadata": {},
   "source": [
    "Critical fix starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "997b09e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force IDs to be strings in both dataframes , this is very important for pyterrier to read things correctly\n",
    "queries_df = queries_df.assign(\n",
    "    qid = queries_df['query_id'].astype(str),\n",
    "    query = queries_df['question'].astype(str)\n",
    ")\n",
    "\n",
    "qrels_df = qrels_df.assign(\n",
    "    qid = qrels_df['query_id'].astype(str),\n",
    "    docno = qrels_df['para_id'].astype(str),\n",
    "    label = qrels_df['relevance'].astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54b53a3",
   "metadata": {},
   "source": [
    "## Baseline 1: Character N-Gram Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f33336",
   "metadata": {},
   "source": [
    "Define a function to convert text into character n-grams:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a1420",
   "metadata": {},
   "source": [
    "In this function, we remove the stop words before creating the n-grams. To implement this, we use the NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ab433",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = set([\"the\", \"and\", \"is\", \"of\", \"in\", \"to\", \"a\", \"it\", \"that\", \"for\", \"on\", \n",
    "                 \"with\", \"as\", \"by\", \"at\", \"an\", \"be\", \"this\", \"which\", \"or\", \"from\", \n",
    "                 \"what\", \"where\", \"when\", \"who\", \"how\", \"why\"])\n",
    "\n",
    "def to_ngrams(text, n=3):\n",
    "    \"\"\"\n",
    "    Converts a string into a space-separated sequence of character n-grams\n",
    "    \"\"\"\n",
    "    if pd.isna(text) or text == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "\n",
    "    # Remove non-alphanumeric chars\n",
    "    text = re.sub(r'[^a-z0-9 ]', ' ', text)\n",
    "\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Check against the NLTK set\n",
    "    clean_words = [w for w in words if w not in STOPWORDS and len(w) > 1]\n",
    "\n",
    "    # 4. Join back together\n",
    "    clean_text = \" \".join(clean_words)\n",
    "\n",
    "    # add padding to shorter words\n",
    "    if len(clean_text) < n:\n",
    "        return clean_text + (\"_\" * (n - len(clean_text)))\n",
    "  \n",
    "    # Generate n-grams\n",
    "    ngrams = [clean_text[i : i+n] for i in range(len(clean_text) - n + 1)]\n",
    "\n",
    "    # Replace spaces with underscores\n",
    "    valid_ngrams = [x.replace(\" \", \"_\") for x in ngrams]\n",
    "\n",
    "    return \" \".join(valid_ngrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1176d98",
   "metadata": {},
   "source": [
    "### 4-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e309bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'docno': 'New_Hampshire_18070804_1', 'text': 'aisc isce scel cell ella llan lane aneo neou eous ous_ us_r s_re _rep repo epos posi osit sito itor tory ory_ ry_a y_al _alb alba lban bany any_ ny_r y_re _reg regi egis gist iste ster ter_ er_w r_wa _war war_ ar_p r_pr _pro pros rosp ospe spec pect ect_ ct_r t_re _rec rece ecen cent ent_ nt_i t_in _ins inst nsta stan tanc ance nces ces_ es_b s_br _bri brit riti itis tish ish_ sh_o h_ou _out outr utra trag rage age_ ge_w e_wi _wil will illi llia liam iam_ am_r m_ra _ray ray_ ay_a y_au _aut auth utho thor hor_ or_c r_co _con cont onte ntem temp empl mpla plat late ated ted_ ed_p d_pu _pub publ ubli blic lica icat cati atio tion ion_ on_e n_en _ent enti ntit titl itle tled led_ ed_h d_ho _hor horr orro rror rors ors_ rs_s s_sl _sla slav lave aver very ery_ ry_a y_am _ame amer meri eric rica ican can_ an_t n_tu _tur turf urf_ rf_t f_tr _tri trip ripo ipol poli oli_ li_v i_vo _vot vota otar tari arie ries ies_ es_f s_fr _fre free reed eedo edom dom_ om_a m_ar _arm arm_ rm_b m_br _bri brit riti itis tish ish_ sh_l h_li _lio lion ion_ on_r n_ro _roa roar oars ars_ rs_l s_le _leg legi egio gion ions ons_ ns_v s_va _val valo alor lor_ or_t r_ta _tak take ake_ ke_t e_th _th_ th_a h_al _ala alar larm arm_ rm_r m_ra _ras rash ash_ sh_r h_ru _rus rush ush_ sh_g h_gu _gua guar uard ard_ rd_o d_ou _our our_ ur_s r_sh _sho shor hore ores res_ es_b s_be _beh beho ehol hold old_ ld_h d_ho _hor horr orri rrid rid_ id_d d_de _dee deed eed_ ed_y d_yo _you your our_ ur_b r_br _bre bret reth ethr thre hren ren_ en_g n_ga _gas gasp aspi spin ping ing_ ng_l g_li _lie lie_ ie_b e_be _ben bene enea neat eath ath_ th_t h_ty _tyr tyra yran rant ant_ nt_h t_ha _han hand and_ nd_t d_th _the they hey_ ey_b y_bl _ble blee leed eed_ ed_t d_th _the they hey_ ey_g y_gr _gro groa roan oan_ an_t n_th _the they hey_ ey_f y_fa _fai fain aint int_ nt_t t_th _the they hey_ ey_d y_di _die die_ ie_v e_ve _vet vete eter tera eran rans ans_ ns_s s_se _sev seve even vent enty nty_ ty_s y_si _six six_ ix_a x_aw _awa awak wake ake_ ke_s e_sl _slu slum lumb umbe mber beri erin ring ing_ ng_s g_sw _swo swor word ord_ rd_h d_he _hea hear eart arts rts_ ts_y s_yo _you your our_ ur_m r_mu _mur murd urde rder dero erou rous ous_ us_f s_fo _foe foes oes_ es_t s_tr _tra tran rans ansf nsfi sfix fix_ ix_t x_ti _tis tis_ is_v s_ve _ven veng enge ngea gean eanc ance nce_ ce_g e_gi _giv give ives ves_ es_w s_wo _wor word ord_ rd_r d_re _rem reme emem memb embe mber ber_ er_l r_le _lex lexi exin xing ingt ngto gton ton_ on_b n_bu _bun bunk unke nker ker_ er_t r_tr _tra trag ragi agic gic_ ic_h c_hi _hil hill ill_ ll_s l_sa _sam same ame_ me_s e_sp _spi spil pilt ilt_ lt_y t_yo _you your our_ ur_b r_bl _blo bloo lood ood_ od_t d_th _the ther here ereo reon eon_ on_y n_yo _you your our_ ur_b r_bl _blo bloo lood ood_ od_a d_ag _aga agai gain ain_ in_w n_wo _wou woul ould uld_ ld_s d_sp _spi spil pill ill_ ll_y l_ye _ye_ ye_h e_ha _hav have ave_ ve_s e_se _see seen een_ en_y n_yo _you your our_ ur_w r_wi _wiv wive ives ves_ es_y s_yo _you your our_ ur_c r_ch _chi chil hild ildr ldre dren ren_ en_y n_yo _you your our_ ur_f r_fi _fir fire ires res_ es_t s_to _too too_ oo_b o_br _bri brit riti itis tish ish_ sh_r h_ru _ruf ruff uffi ffia fian ians ans_ ns_y s_yi _yie yiel ield eld_ ld_t d_th _the thei heir eir_ ir_l r_li _liv live ives ves_ es_r s_ro _roa roas oast ast_ st_s t_sa _sav sava avag vage age_ ge_f e_fi _fir fire ires res_ es_o s_ou _our our_ ur_c r_ci _cit citi itie ties ies_ es_l s_lo _los lost ost_ st_f t_fl _fla flam lame ames mes_ es_y s_yo _you your our_ ur_m r_mo _mot moth othe ther hers ers_ rs_c s_ca _cap capt apti ptiv tive ive_ ve_l e_le _led led_ ed_r d_ri _ris rise ise_ se_a e_av _ave aven veng enge nge_ ge_t e_th _the thei heir eir_ ir_i r_in _inj inju njur jure ured red_ ed_n d_na _nam name ames mes_ es_y s_ye _ye_ ye_k e_ki _kin kind indr ndre dred red_ ed_d d_de _dea dead ead_ ad_b d_bu _but but_ ut_n t_no _not not_ ot_r t_re _rev reve even veng enge nge_ ge_a e_al _alo alon lone one_ ne_s e_sh _sho shou houl ould uld_ ld_u d_ur _urg urge rge_ ge_y e_yo _you you_ ou_f u_fi _fie fiel ield eld_ ld_l d_le _let let_ et_d t_du _dut duty uty_ ty_l y_le _lea lead ead_ ad_y d_yo _you you_ ou_f u_fi _fir firm irml rmly mly_ ly_j y_ju _jus just usti stic tice ice_ ce_y e_yo _you your our_ ur_s r_sh _shi shie hiel ield eld_ ld_s d_su _sur sure ure_ re_w e_we _we_ we_f e_fa _fai fail ail_ il_j l_jo _joi join oin_ in_c n_cr _cru crus rush ush_ sh_o h_ou _our our_ ur_i r_im _imp impi mpio piou ious ous_ us_f s_fo _foe foes oes_ es_w s_wa _war war_ ar_f r_fi _fir fire ire_ re_s e_sw _swo swor word ord_ rd_d d_de _dea deat eath ath_ th_c h_co _com comb ombi mbin bine ine_ ne_w e_wo _woe woes oes_ es_s s_su _suc succ ucce ccee ceed eed_ ed_w d_wo _woe woes'}, {'docno': 'New_Hampshire_18070804_4', 'text': 'sure urel rely ely_ ly_h y_he _he_ he_a e_ab _abo abov bove ove_ ve_r e_re _res rest est_ st_h t_hi _his his_ is_f s_fe _fel fell ello llow low_ ow_m w_mo _mor mort orta rtal tals als_ ls_p s_pa _par part arta rtak take akes kes_ es_h s_he _hea heav eave aven ven_ en_h n_he _her here ere_ re_b e_be _bel belo elow low_ ow_b w_bl _bli blis liss iss_ ss_n s_no _non none one_ ne_b e_bu _but but_ ut_v t_vi _vir virt irtu rtuo tuou uous ous_ us_e s_ev _eve ever ver_ er_c r_cl _cla clai laim aim_ im_o m_ob _obi obit bitu itua tuar uary ary_ ry_f y_fr _fra fran ranc ance nce_ ce_g e_ge _gen gen_ en_d n_de _de_ de_r e_ro _ros rose osem semb embe mber berg erg_ rg_a g_ag _age aged ged_ ed_8 d_83 _83_ 83_f 3_fo _for form orme rmer merl erly rly_ ly_m y_ma _mar mars arsh rsha shal hal_ al_f l_fr _fra fran ranc ance nce_ ce_g e_gr _gra gran rand and_ nd_o d_of _off offi ffic fice icer cer_ er_l r_le _leg legi egio gion ion_ on_h n_ho _hon hono onor nor_ or_c r_co _com comm omma mman mand ande nder der_ er_f r_fr _fre fren renc ench nch_ ch_t h_tr _tro troo roop oops ops_ ps_u s_un _uni unit nite ited ted_ ed_s d_st _sta stat tate ates tes_ es_d s_du _dur duri urin ring ing_ ng_r g_re _rev revo evol volu olut luti utio tion iona onar nary ary_ ry_w y_wa _war war_ ar_w r_wa _was wash ashi shin hing ingt ngto gton ton_ on_h n_ho _hon hon_ on_u n_ur _uri uria riah iah_ ah_t h_tr _tra trac racy acy_ cy_e y_es _esq esq_ sq_s q_se _sen sena enat nato ator tor_ or_u r_un _uni unit nite ited ted_ ed_s d_st _sta stat tate ates tes_ es_s s_st _sta stat tate ate_ te_c e_co _con conn onne nnec nect ecti ctic ticu icut cut_ ut_a t_ag _age aged ged_ ed_5 d_54 _54_ 54_h 4_hi _his his_ is_p s_pa _pal pall all_ ll_w l_wa _was was_ as_s s_su _sup supp uppo ppor port orte rted ted_ ed_h d_he _hea head eads ads_ ds_d s_de _dep depa epar part artm rtme tmen ment ent_ nt_o t_of _off offi ffic fice icer cers ers_ rs_g s_go _gov gove over vern ernm rnme nmen ment ent_ nt_h t_he _he_ he_h e_ha _had had_ ad_b d_be _bee been een_ en_s n_si _sic sick ick_ ck_w k_wa _was wash ashi shin hing ingt ngto gton ton_ on_s n_si _sin sinc ince nce_ ce_m e_ma _mar marc arch rch_ ch_l h_la _las last ast_ st_b t_ba _bal balt alti ltim timo imor more ore_ re_d e_du _dur duri urin ring ing_ ng_w g_we _wee week eek_ ek_e k_en _end endi ndin ding ing_ ng_1 g_18 _18t 18th 8th_ th_u h_ul _ult ult_ lt_1 t_15 _15_ 15_a 5_ad _adu adul dult ults lts_ ts_2 s_23 _23_ 23_c 3_ch _chi chil hild ildr ldre dren ren_ en_p n_ph _phi phil hila ilad lade adel delp elph lphi phia hia_ ia_d a_du _dur duri urin ring ing_ ng_w g_we _wee week eek_ ek_e k_en _end endi ndin ding ing_ ng_1 g_18 _18t 18th 8th_ th_u h_ul _ult ult_ lt_2 t_24 _24_ 24_a 4_ad _adu adul dult ults lts_ ts_4 s_40 _40_ 40_c 0_ch _chi chil hild ildr ldre dren ren_ en_n n_ne _new new_ ew_y w_yo _yor york ork_ rk_d k_du _dur duri urin ring ing_ ng_w g_we _wee week eek_ ek_e k_en _end endi ndin ding ing_ ng_1 g_18 _18t 18th 8th_ th_u h_ul _ult ult_ lt_m t_me _men men_ en_w n_wo _wom wome omen men_ en_1 n_10 _10_ 10_b 0_bo _boy boys oys_ ys_g s_gi _gir girl irls rls_ ls_n s_ne _new newa ewar wark ark_ rk_r k_re _rev rev_ ev_d v_dr _dr_ dr_a r_al _ale alex lexa exan xand ande nder der_ er_m r_ma _mac maca acau caul aule uley ley_ ey_a y_ag _age aged ged_ ed_7 d_73 _73_ 73_d 3_da _dan danv anve nver vers ers_ rs_d s_dr _dr_ dr_a r_am _amo amos mos_ os_p s_pu _put putn utna tnam nam_ am_a m_ag _age aged ged_ ed_8 d_83 _83_ 83_a 3_an _and ando ndov dove over ver_ er_m r_mr _mrs mrs_ rs_s s_su _sus susa usan sann anna nna_ na_s a_sy _sym symm ymme mmes mes_ es_r s_re _rel reli elic lict ict_ ct_l t_la _lat late ate_ te_r e_re _rev rev_ ev_d v_dr _dr_ dr_w r_wm _wm_ wm_s m_sy _sym symm ymme mmes mes_ es_a s_ag _age aged ged_ ed_7 d_79 _79_ 79_s 9_sa _sal sale alem lem_ em_m m_ma _mas mass ass_ ss_w s_wi _wid wido idow dow_ ow_m w_ma _mar marg arga rgar gare aret ret_ et_s t_sw _swa swaf waff affe ffey fey_ ey_a y_ag _age aged ged_ ed_1 d_10 _100 100_ 00_y 0_ye _yea year ears ars_ rs_m s_mo _mon mont onth nths ths_ hs_n s_ne _new newb ewbu wbur bury uryp rypo ypor port ort_ rt_m t_mr _mr_ mr_s r_sa _sam samu amue muel uel_ el_d l_de _dex dext exte xter ter_ er_a r_ag _age aged ged_ ed_3 d_36 _36_ 36_o 6_on _onl only nly_ ly_s y_so _son son_ on_l n_la _lat late ate_ te_l e_lo _lor lord ord_ rd_d d_de _dex dext exte xter ter_ er_b r_br _bru brun runs unsw nswi swic wick ick_ ck_r k_re _rev rev_ ev_j v_jo _jos jose osep seph eph_ ph_m h_mc _mck mcke ckea kean ean_ an_l n_la _lat late ate_ te_p e_pr _pre pres resi esid side iden dent ent_ nt_b t_bo _bow bowd owdo wdoi doin oin_ in_c n_co _col coll olle lleg lege ege_ ge_l e_la _lan lanc anca ncas cast aste ster ter_ er_m r_mr _mr_ mr_h r_he _hen henr enry nry_ ry_h y_ha _has hask aske skel kell ell_ ll_a l_ag _age aged ged_ ed_7 d_73 _73_ 73_l 3_lt _lt_ lt_c t_co _col col_ ol_r l_re _rev revo evol volu olut luti utio tion iona onar nary ary_ ry_a y_ar _arm army rmy_ my_c y_ch _che ches hest este ster terf erfi rfie fiel ield eld_ ld_m d_mr _mrs mrs_ rs_l s_lo _lou loui ouis uisa isa_ sa_p a_pa _par pars arso rson sons ons_ ns_w s_wi _wif wife ife_ fe_b e_be _ben benj enja njam jami amin min_ in_p n_pa _par pars arso rson sons ons_ ns_e s_es _esq esq_ sq_a q_ag _age aged ged_ ed_3 d_39'}, {'docno': 'New_Hampshire_18070804_5', 'text': 'west estm stmo tmor more orel rela elan land and_ nd_m d_mr _mrs mrs_ rs_s s_sa _sal sall ally lly_ ly_l y_li _lin linc inco ncol coln oln_ ln_w n_wi _wif wife ife_ fe_m e_mr _mr_ mr_s r_sp _spe spen penc ence ncer cer_ er_a r_ag _age aged ged_ ed_2 d_28 _28_ 28_h 8_he _hen henr enri nric rico ico_ co_m o_mr _mrs mrs_ rs_p s_po _pol poll olly lly_ ly_a y_ad _ada adam dams ams_ ms_c s_co _con cons onso nsor sort ort_ rt_s t_sa _sat satu atur turd urda rday day_ ay_1 y_11 _11t 11th 1th_ th_u h_ul _ult ult_ lt_m t_mr _mr_ mr_j r_jo _jos jose osep seph eph_ ph_m h_me _mey meye eyer yer_ er_h r_ha _ham hamp amps mpst pste stea tead ead_ ad_w d_wa _was was_ as_f s_fo _fou foun ound und_ nd_d d_de _dea dead ead_ ad_r d_ro _roa road oad_ ad_h d_hi _his his_ is_h s_ho _hor hors orse rse_ se_s e_st _sta stan tand andi ndin ding ing_ ng_h g_hi _him him_ im_o m_oy _oy_ oy_s y_sm _smi smit mith ith_ th_r h_ru _rus rust ust_ st_p t_po _poc pock ocke cket ket_ et_b t_bo _boo book ook_ ok_l k_lo _los lost ost_ st_l t_lo _los lost ost_ st_l t_la _las last ast_ st_w t_we _wed wedn edne dnes nesd esda sday day_ ay_b y_be _bet betw etwe twee ween een_ en_c n_cl _clo cloc lock ock_ ck_a k_af _aft afte fter tern erno rnoo noon oon_ on_e n_ei _eit eith ithe ther her_ er_g r_gl _glo glob lobe obe_ be_t e_ta _tav tave aver vern ern_ rn_p n_pl _pla plai lain ains ins_ ns_r s_ro _roa road oad_ ad_l d_le _lea lead eadi adin ding ing_ ng_t g_th _the then henc ence nce_ ce_p e_po _por port orts rtsm tsmo smou mout outh uth_ th_n h_ne _new new_ ew_r w_re _red red_ ed_m d_mo _mor moro oroc rocc occo cco_ co_p o_po _poc pock ocke cket ket_ et_b t_bo _boo book ook_ ok_c k_co _con cont onta ntai tain aini inin ning ing_ ng_s g_so _som some ome_ me_m e_mo _mon mone oney ney_ ey_n y_no _not note otes tes_ es_h s_ha _han hand and_ nd_p d_pa _pay paya ayab yabl able ble_ le_s e_su _sub subs ubsc bscr scri crib ribe iber ber_ er_a r_al _als also lso_ so_n o_ne _new new_ ew_h w_ha _ham hamp amps mpsh pshi shir hire ire_ re_f e_fi _fir fire ire_ re_m e_ma _mar mari arin rine ine_ ne_c e_ce _cer cert erti rtif tifi ific fica icat cate ates tes_ es_o s_ot _oth othe ther her_ er_p r_pa _pap pape aper pers ers_ rs_v s_va _val valu alua luab uabl able ble_ le_n e_no _non none one_ ne_b e_bu _but but_ ut_o t_ow _own owne wner ner_ er_w r_wh _who whoe hoev oeve ever ver_ er_s r_sh _sha shal hall all_ ll_f l_fi _fin find ind_ nd_s d_sa _sai said aid_ id_p d_po _poc pock ocke cket ket_ et_b t_bo _boo book ook_ ok_r k_re _re_ re_t e_tu _tur turn urn_ rn_i n_it _its its_ ts_c s_co _con cont onte nten tent ents nts_ ts_w s_wi _wit with itho thou hout out_ ut_m t_mo _mon mone oney ney_ ey_s y_sh _sha shal hall all_ ll_h l_ha _han hand ands ndso dsom some omel mely ely_ ly_r y_re _rew rewa ewar ward arde rded ded_ ed_t d_th _tha than hank anks nks_ ks_t s_th _the thei heir eir_ ir_h r_hu _hum humb umbl mble ble_ le_s e_se _ser serv erva rvan vant ant_ nt_e t_ed _edw edwa dwar ward ard_ rd_p d_pa _par parr arry rry_ ry_l y_le _let let_ et_f t_fi _fir fire irep repr epro proo roof oof_ of_s f_st _sto stor tore ore_ re_l e_la _lat late atel tely ely_ ly_i y_im _imp impr mpro prov rove oved ved_ ed_m d_mr _mr_ mr_b r_be _ben benj enja njam jami amin min_ in_s n_sw _swe swet wett ett_ tt_m t_mu _mus must ust_ st_a t_al _all allo llow lowe owed wed_ ed_b d_be _bes best est_ st_s t_st _sta stan tand and_ nd_b d_bu _bus busi usin sine ines ness ess_ ss_e s_ei _eit eith ithe ther her_ er_e r_en _eng engl ngli glis lish ish_ sh_w h_we _wes west est_ st_i t_in _ind indi ndia dia_ ia_g a_go _goo good oods ods_ ds_t s_to _tow town own_ wn_i n_in _inq inqu nqui quir uire ire_ re_e e_ed _edw edwa dwar ward ard_ rd_p d_pa _par parr arry rry_ ry_h y_ha _has has_ as_l s_la _lar larg arge rge_ ge_a e_as _ass asso ssor sort ortm rtme tmen ment ent_ nt_f t_fa _fas fash ashi shio hion iona onab nabl able ble_ le_g e_go _goo good oods ods_ ds_s s_sa _sal sale ale_ le_c e_ch _che chea heap eap_ ap_c p_ca _cas cash ash_ sh_s h_sh _sho shor hort ort_ rt_c t_cr _cre cred redi edit dit_ it_j t_ju _jul july uly_ ly_2 y_28 _28_ 28_s 8_sa _sal sale ale_ le_n e_ne _new new_ ew_g w_go _gon gond ondo ndol dola ola_ la_b a_bu _bui buil uilt ilt_ lt_b t_be _bes best est_ st_m t_ma _mat mate ater teri eria rial ials als_ ls_e s_ex _exp expe xper peri erie rien ienc ence nced ced_ ed_w d_wo _wor work orkm rkma kman man_ an_f n_fo _for fort orty rty_ ty_f y_fe _fee feet eet_ et_c t_co _cor cor_ or_n r_ne _ner ner_ er_p r_pi _pie piec iece ece_ ce_f e_fu _fur furt urth rthe ther her_ er_p r_pa _par part arti rtic ticu icul cula ular lars ars_ rs_e s_en _enq enqu nqui quir uire ire_ re_m e_mi _mic mich icha chae hael ael_ el_w l_wi _wig wigg iggi ggin gin_ in_n n_ne _new newm ewma wmar mark arke rket ket_ et_j t_ju _jul july uly_ ly_2 y_27 _27t 27th 7th_ th_1 h_18 _180 1807 807_ 07_c 7_ch _cha chai hais aise'}]\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['context'].fillna(\"\").astype(str).apply(lambda x: to_ngrams(x, n=4))\n",
    "\n",
    "docs = df[[\"docno\", \"text\"]].to_dict(\"records\")\n",
    "print(docs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3b5ac7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzzy_query created:\n",
      "   query_id                                           question       qid  \\\n",
      "0    test_1               How many lots did Thomas Peirce have    test_1   \n",
      "1   test_10  Who gave Hamilton the substance of what he had...   test_10   \n",
      "2  test_100  Who informs his FRIENDS and the PUBLIC that he...  test_100   \n",
      "\n",
      "                                               query  \n",
      "0  many any_ ny_l y_lo _lot lots ots_ ts_d s_di _...  \n",
      "1  gave ave_ ve_h e_ha _ham hami amil milt ilto l...  \n",
      "2  info nfor form orms rms_ ms_h s_hi _his his_ i...  \n"
     ]
    }
   ],
   "source": [
    "fuzzy_query = queries_df.copy()\n",
    "fuzzy_query['query'] = fuzzy_query['query'].apply(lambda x: to_ngrams(x, n=4))\n",
    "\n",
    "# Sanity Check\n",
    "print(\"fuzzy_query created:\")\n",
    "print(fuzzy_query.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4dd38",
   "metadata": {},
   "source": [
    "Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4d5d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing complete\n"
     ]
    }
   ],
   "source": [
    "INDEX_FUZZY_PATH = \"./indices/fuzzy_index_v1\"\n",
    "\n",
    "# Disable stemming and stopwords\n",
    "\n",
    "indexer_fuzzy = pt.index.IterDictIndexer(\n",
    "    INDEX_FUZZY_PATH,\n",
    "    meta={\"docno\": 50},\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Set properties to disable standard English processing\n",
    "indexer_fuzzy.setProperty(\"termpipelines\", \"\") \n",
    "indexer_fuzzy.setProperty(\"tokeniser\", \"WhitespaceTokeniser\") # Split only on the spaces we added\n",
    "\n",
    "indexref = indexer_fuzzy.index(docs)\n",
    "index_fuzzy = pt.IndexFactory.of(indexref)\n",
    "\n",
    "print(\"Indexing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03620c64",
   "metadata": {},
   "source": [
    "Then we use the BM25 Retriever on the fuzzy index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66c06451",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_fuzzy = pt.terrier.Retriever(\n",
    "    index_fuzzy, \n",
    "    wmodel=\"BM25\", \n",
    "    properties={\"termpipelines\": \"\", \"tokeniser\": \"WhitespaceTokeniser\"}, # must match indexing\n",
    "    verbose=True # Shows a progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73a50ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 100 queries\n",
    "test_slice = 100\n",
    "test_queries = fuzzy_query[:test_slice]\n",
    "\n",
    "relevant_qids = test_queries['qid'].values\n",
    "filtered_qrels = qrels_df[qrels_df['qid'].isin(relevant_qids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89b0821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TerrierRetr(BM25): 100%|██████████| 100/100 [00:10<00:00,  9.15q/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_results = bm25_fuzzy.transform(test_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78c31b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier.measures import R, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a90d3ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R@1': 0.71, 'R@100': 0.93, 'AP': 0.763444712518693}\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate\n",
    "eval_metrics = pt.Evaluate(\n",
    "    bm25_results,\n",
    "    filtered_qrels,\n",
    "    metrics=[R@1, R@100, MAP]\n",
    ")\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dc929f",
   "metadata": {},
   "source": [
    "### 5-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106a698",
   "metadata": {},
   "source": [
    "Let's try 5-grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc96862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'docno': 'New_Hampshire_18070804_1', 'text': 'aisce iscel scell cella ellan llane laneo aneou neous eous_ ous_r us_re s_rep _repo repos eposi posit osito sitor itory tory_ ory_a ry_al y_alb _alba alban lbany bany_ any_r ny_re y_reg _regi regis egist giste ister ster_ ter_w er_wa r_war _war_ war_p ar_pr r_pro _pros prosp rospe ospec spect pect_ ect_r ct_re t_rec _rece recen ecent cent_ ent_i nt_in t_ins _inst insta nstan stanc tance ances nces_ ces_b es_br s_bri _brit briti ritis itish tish_ ish_o sh_ou h_out _outr outra utrag trage rage_ age_w ge_wi e_wil _will willi illia lliam liam_ iam_r am_ra m_ray _ray_ ray_a ay_au y_aut _auth autho uthor thor_ hor_c or_co r_con _cont conte ontem ntemp templ empla mplat plate lated ated_ ted_p ed_pu d_pub _publ publi ublic blica licat icati catio ation tion_ ion_e on_en n_ent _enti entit ntitl title itled tled_ led_h ed_ho d_hor _horr horro orror rrors rors_ ors_s rs_sl s_sla _slav slave laver avery very_ ery_a ry_am y_ame _amer ameri meric erica rican ican_ can_t an_tu n_tur _turf turf_ urf_t rf_tr f_tri _trip tripo ripol ipoli poli_ oli_v li_vo i_vot _vota votar otari tarie aries ries_ ies_f es_fr s_fre _free freed reedo eedom edom_ dom_a om_ar m_arm _arm_ arm_b rm_br m_bri _brit briti ritis itish tish_ ish_l sh_li h_lio _lion lion_ ion_r on_ro n_roa _roar roars oars_ ars_l rs_le s_leg _legi legio egion gions ions_ ons_v ns_va s_val _valo valor alor_ lor_t or_ta r_tak _take take_ ake_t ke_th e_th_ _th_a th_al h_ala _alar alarm larm_ arm_r rm_ra m_ras _rash rash_ ash_r sh_ru h_rus _rush rush_ ush_g sh_gu h_gua _guar guard uard_ ard_o rd_ou d_our _our_ our_s ur_sh r_sho _shor shore hores ores_ res_b es_be s_beh _beho behol ehold hold_ old_h ld_ho d_hor _horr horri orrid rrid_ rid_d id_de d_dee _deed deed_ eed_y ed_yo d_you _your your_ our_b ur_br r_bre _bret breth rethr ethre thren hren_ ren_g en_ga n_gas _gasp gaspi aspin sping ping_ ing_l ng_li g_lie _lie_ lie_b ie_be e_ben _bene benea eneat neath eath_ ath_t th_ty h_tyr _tyra tyran yrant rant_ ant_h nt_ha t_han _hand hand_ and_t nd_th d_the _they they_ hey_b ey_bl y_ble _blee bleed leed_ eed_t ed_th d_the _they they_ hey_g ey_gr y_gro _groa groan roan_ oan_t an_th n_the _they they_ hey_f ey_fa y_fai _fain faint aint_ int_t nt_th t_the _they they_ hey_d ey_di y_die _die_ die_v ie_ve e_vet _vete veter etera teran erans rans_ ans_s ns_se s_sev _seve seven event venty enty_ nty_s ty_si y_six _six_ six_a ix_aw x_awa _awak awake wake_ ake_s ke_sl e_slu _slum slumb lumbe umber mberi berin ering ring_ ing_s ng_sw g_swo _swor sword word_ ord_h rd_he d_hea _hear heart earts arts_ rts_y ts_yo s_you _your your_ our_m ur_mu r_mur _murd murde urder rdero derou erous rous_ ous_f us_fo s_foe _foes foes_ oes_t es_tr s_tra _tran trans ransf ansfi nsfix sfix_ fix_t ix_ti x_tis _tis_ tis_v is_ve s_ven _veng venge engea ngean geanc eance ance_ nce_g ce_gi e_giv _give gives ives_ ves_w es_wo s_wor _word word_ ord_r rd_re d_rem _reme remem ememb membe ember mber_ ber_l er_le r_lex _lexi lexin exing xingt ingto ngton gton_ ton_b on_bu n_bun _bunk bunke unker nker_ ker_t er_tr r_tra _trag tragi ragic agic_ gic_h ic_hi c_hil _hill hill_ ill_s ll_sa l_sam _same same_ ame_s me_sp e_spi _spil spilt pilt_ ilt_y lt_yo t_you _your your_ our_b ur_bl r_blo _bloo blood lood_ ood_t od_th d_the _ther there hereo ereon reon_ eon_y on_yo n_you _your your_ our_b ur_bl r_blo _bloo blood lood_ ood_a od_ag d_aga _agai again gain_ ain_w in_wo n_wou _woul would ould_ uld_s ld_sp d_spi _spil spill pill_ ill_y ll_ye l_ye_ _ye_h ye_ha e_hav _have have_ ave_s ve_se e_see _seen seen_ een_y en_yo n_you _your your_ our_w ur_wi r_wiv _wive wives ives_ ves_y es_yo s_you _your your_ our_c ur_ch r_chi _chil child hildr ildre ldren dren_ ren_y en_yo n_you _your your_ our_f ur_fi r_fir _fire fires ires_ res_t es_to s_too _too_ too_b oo_br o_bri _brit briti ritis itish tish_ ish_r sh_ru h_ruf _ruff ruffi uffia ffian fians ians_ ans_y ns_yi s_yie _yiel yield ield_ eld_t ld_th d_the _thei their heir_ eir_l ir_li r_liv _live lives ives_ ves_r es_ro s_roa _roas roast oast_ ast_s st_sa t_sav _sava savag avage vage_ age_f ge_fi e_fir _fire fires ires_ res_o es_ou s_our _our_ our_c ur_ci r_cit _citi citie ities ties_ ies_l es_lo s_los _lost lost_ ost_f st_fl t_fla _flam flame lames ames_ mes_y es_yo s_you _your your_ our_m ur_mo r_mot _moth mothe other thers hers_ ers_c rs_ca s_cap _capt capti aptiv ptive tive_ ive_l ve_le e_led _led_ led_r ed_ri d_ris _rise rise_ ise_a se_av e_ave _aven aveng venge enge_ nge_t ge_th e_the _thei their heir_ eir_i ir_in r_inj _inju injur njure jured ured_ red_n ed_na d_nam _name names ames_ mes_y es_ye s_ye_ _ye_k ye_ki e_kin _kind kindr indre ndred dred_ red_d ed_de d_dea _dead dead_ ead_b ad_bu d_but _but_ but_n ut_no t_not _not_ not_r ot_re t_rev _reve reven eveng venge enge_ nge_a ge_al e_alo _alon alone lone_ one_s ne_sh e_sho _shou shoul hould ould_ uld_u ld_ur d_urg _urge urge_ rge_y ge_yo e_you _you_ you_f ou_fi u_fie _fiel field ield_ eld_l ld_le d_let _let_ let_d et_du t_dut _duty duty_ uty_l ty_le y_lea _lead lead_ ead_y ad_yo d_you _you_ you_f ou_fi u_fir _firm firml irmly rmly_ mly_j ly_ju y_jus _just justi ustic stice tice_ ice_y ce_yo e_you _your your_ our_s ur_sh r_shi _shie shiel hield ield_ eld_s ld_su d_sur _sure sure_ ure_w re_we e_we_ _we_f we_fa e_fai _fail fail_ ail_j il_jo l_joi _join join_ oin_c in_cr n_cru _crus crush rush_ ush_o sh_ou h_our _our_ our_i ur_im r_imp _impi impio mpiou pious ious_ ous_f us_fo s_foe _foes foes_ oes_w es_wa s_war _war_ war_f ar_fi r_fir _fire fire_ ire_s re_sw e_swo _swor sword word_ ord_d rd_de d_dea _deat death eath_ ath_c th_co h_com _comb combi ombin mbine bine_ ine_w ne_wo e_woe _woes woes_ oes_s es_su s_suc _succ succe uccee cceed ceed_ eed_w ed_wo d_woe _woes'}, {'docno': 'New_Hampshire_18070804_4', 'text': 'surel urely rely_ ely_h ly_he y_he_ _he_a he_ab e_abo _abov above bove_ ove_r ve_re e_res _rest rest_ est_h st_hi t_his _his_ his_f is_fe s_fel _fell fello ellow llow_ low_m ow_mo w_mor _mort morta ortal rtals tals_ als_p ls_pa s_par _part parta artak rtake takes akes_ kes_h es_he s_hea _heav heave eaven aven_ ven_h en_he n_her _here here_ ere_b re_be e_bel _belo below elow_ low_b ow_bl w_bli _blis bliss liss_ iss_n ss_no s_non _none none_ one_b ne_bu e_but _but_ but_v ut_vi t_vir _virt virtu irtuo rtuou tuous uous_ ous_e us_ev s_eve _ever ever_ ver_c er_cl r_cla _clai claim laim_ aim_o im_ob m_obi _obit obitu bitua ituar tuary uary_ ary_f ry_fr y_fra _fran franc rance ance_ nce_g ce_ge e_gen _gen_ gen_d en_de n_de_ _de_r de_ro e_ros _rose rosem osemb sembe ember mberg berg_ erg_a rg_ag g_age _aged aged_ ged_8 ed_83 d_83_ _83_f 83_fo 3_for _form forme ormer rmerl merly erly_ rly_m ly_ma y_mar _mars marsh arsha rshal shal_ hal_f al_fr l_fra _fran franc rance ance_ nce_g ce_gr e_gra _gran grand rand_ and_o nd_of d_off _offi offic ffice ficer icer_ cer_l er_le r_leg _legi legio egion gion_ ion_h on_ho n_hon _hono honor onor_ nor_c or_co r_com _comm comma omman mmand mande ander nder_ der_f er_fr r_fre _fren frenc rench ench_ nch_t ch_tr h_tro _troo troop roops oops_ ops_u ps_un s_uni _unit unite nited ited_ ted_s ed_st d_sta _stat state tates ates_ tes_d es_du s_dur _duri durin uring ring_ ing_r ng_re g_rev _revo revol evolu volut oluti lutio ution tiona ionar onary nary_ ary_w ry_wa y_war _war_ war_w ar_wa r_was _wash washi ashin shing hingt ingto ngton gton_ ton_h on_ho n_hon _hon_ hon_u on_ur n_uri _uria uriah riah_ iah_t ah_tr h_tra _trac tracy racy_ acy_e cy_es y_esq _esq_ esq_s sq_se q_sen _sena senat enato nator ator_ tor_u or_un r_uni _unit unite nited ited_ ted_s ed_st d_sta _stat state tates ates_ tes_s es_st s_sta _stat state tate_ ate_c te_co e_con _conn conne onnec nnect necti ectic cticu ticut icut_ cut_a ut_ag t_age _aged aged_ ged_5 ed_54 d_54_ _54_h 54_hi 4_his _his_ his_p is_pa s_pal _pall pall_ all_w ll_wa l_was _was_ was_s as_su s_sup _supp suppo uppor pport porte orted rted_ ted_h ed_he d_hea _head heads eads_ ads_d ds_de s_dep _depa depar epart partm artme rtmen tment ment_ ent_o nt_of t_off _offi offic ffice ficer icers cers_ ers_g rs_go s_gov _gove gover overn vernm ernme rnmen nment ment_ ent_h nt_he t_he_ _he_h he_ha e_had _had_ had_b ad_be d_bee _been been_ een_s en_si n_sic _sick sick_ ick_w ck_wa k_was _wash washi ashin shing hingt ingto ngton gton_ ton_s on_si n_sin _sinc since ince_ nce_m ce_ma e_mar _marc march arch_ rch_l ch_la h_las _last last_ ast_b st_ba t_bal _balt balti altim ltimo timor imore more_ ore_d re_du e_dur _duri durin uring ring_ ing_w ng_we g_wee _week week_ eek_e ek_en k_end _endi endin nding ding_ ing_1 ng_18 g_18t _18th 18th_ 8th_u th_ul h_ult _ult_ ult_1 lt_15 t_15_ _15_a 15_ad 5_adu _adul adult dults ults_ lts_2 ts_23 s_23_ _23_c 23_ch 3_chi _chil child hildr ildre ldren dren_ ren_p en_ph n_phi _phil phila hilad ilade ladel adelp delph elphi lphia phia_ hia_d ia_du a_dur _duri durin uring ring_ ing_w ng_we g_wee _week week_ eek_e ek_en k_end _endi endin nding ding_ ing_1 ng_18 g_18t _18th 18th_ 8th_u th_ul h_ult _ult_ ult_2 lt_24 t_24_ _24_a 24_ad 4_adu _adul adult dults ults_ lts_4 ts_40 s_40_ _40_c 40_ch 0_chi _chil child hildr ildre ldren dren_ ren_n en_ne n_new _new_ new_y ew_yo w_yor _york york_ ork_d rk_du k_dur _duri durin uring ring_ ing_w ng_we g_wee _week week_ eek_e ek_en k_end _endi endin nding ding_ ing_1 ng_18 g_18t _18th 18th_ 8th_u th_ul h_ult _ult_ ult_m lt_me t_men _men_ men_w en_wo n_wom _wome women omen_ men_1 en_10 n_10_ _10_b 10_bo 0_boy _boys boys_ oys_g ys_gi s_gir _girl girls irls_ rls_n ls_ne s_new _newa newar ewark wark_ ark_r rk_re k_rev _rev_ rev_d ev_dr v_dr_ _dr_a dr_al r_ale _alex alexa lexan exand xande ander nder_ der_m er_ma r_mac _maca macau acaul caule auley uley_ ley_a ey_ag y_age _aged aged_ ged_7 ed_73 d_73_ _73_d 73_da 3_dan _danv danve anver nvers vers_ ers_d rs_dr s_dr_ _dr_a dr_am r_amo _amos amos_ mos_p os_pu s_put _putn putna utnam tnam_ nam_a am_ag m_age _aged aged_ ged_8 ed_83 d_83_ _83_a 83_an 3_and _ando andov ndove dover over_ ver_m er_mr r_mrs _mrs_ mrs_s rs_su s_sus _susa susan usann sanna anna_ nna_s na_sy a_sym _symm symme ymmes mmes_ mes_r es_re s_rel _reli relic elict lict_ ict_l ct_la t_lat _late late_ ate_r te_re e_rev _rev_ rev_d ev_dr v_dr_ _dr_w dr_wm r_wm_ _wm_s wm_sy m_sym _symm symme ymmes mmes_ mes_a es_ag s_age _aged aged_ ged_7 ed_79 d_79_ _79_s 79_sa 9_sal _sale salem alem_ lem_m em_ma m_mas _mass mass_ ass_w ss_wi s_wid _wido widow idow_ dow_m ow_ma w_mar _marg marga argar rgare garet aret_ ret_s et_sw t_swa _swaf swaff waffe affey ffey_ fey_a ey_ag y_age _aged aged_ ged_1 ed_10 d_100 _100_ 100_y 00_ye 0_yea _year years ears_ ars_m rs_mo s_mon _mont month onths nths_ ths_n hs_ne s_new _newb newbu ewbur wbury buryp urypo rypor yport port_ ort_m rt_mr t_mr_ _mr_s mr_sa r_sam _samu samue amuel muel_ uel_d el_de l_dex _dext dexte exter xter_ ter_a er_ag r_age _aged aged_ ged_3 ed_36 d_36_ _36_o 36_on 6_onl _only only_ nly_s ly_so y_son _son_ son_l on_la n_lat _late late_ ate_l te_lo e_lor _lord lord_ ord_d rd_de d_dex _dext dexte exter xter_ ter_b er_br r_bru _brun bruns runsw unswi nswic swick wick_ ick_r ck_re k_rev _rev_ rev_j ev_jo v_jos _jose josep oseph seph_ eph_m ph_mc h_mck _mcke mckea ckean kean_ ean_l an_la n_lat _late late_ ate_p te_pr e_pre _pres presi resid eside siden ident dent_ ent_b nt_bo t_bow _bowd bowdo owdoi wdoin doin_ oin_c in_co n_col _coll colle olleg llege lege_ ege_l ge_la e_lan _lanc lanca ancas ncast caste aster ster_ ter_m er_mr r_mr_ _mr_h mr_he r_hen _henr henry enry_ nry_h ry_ha y_has _hask haske askel skell kell_ ell_a ll_ag l_age _aged aged_ ged_7 ed_73 d_73_ _73_l 73_lt 3_lt_ _lt_c lt_co t_col _col_ col_r ol_re l_rev _revo revol evolu volut oluti lutio ution tiona ionar onary nary_ ary_a ry_ar y_arm _army army_ rmy_c my_ch y_che _ches chest heste ester sterf terfi erfie rfiel field ield_ eld_m ld_mr d_mrs _mrs_ mrs_l rs_lo s_lou _loui louis ouisa uisa_ isa_p sa_pa a_par _pars parso arson rsons sons_ ons_w ns_wi s_wif _wife wife_ ife_b fe_be e_ben _benj benja enjam njami jamin amin_ min_p in_pa n_par _pars parso arson rsons sons_ ons_e ns_es s_esq _esq_ esq_a sq_ag q_age _aged aged_ ged_3 ed_39'}, {'docno': 'New_Hampshire_18070804_5', 'text': 'westm estmo stmor tmore morel orela relan eland land_ and_m nd_mr d_mrs _mrs_ mrs_s rs_sa s_sal _sall sally ally_ lly_l ly_li y_lin _linc linco incol ncoln coln_ oln_w ln_wi n_wif _wife wife_ ife_m fe_mr e_mr_ _mr_s mr_sp r_spe _spen spenc pence encer ncer_ cer_a er_ag r_age _aged aged_ ged_2 ed_28 d_28_ _28_h 28_he 8_hen _henr henri enric nrico rico_ ico_m co_mr o_mrs _mrs_ mrs_p rs_po s_pol _poll polly olly_ lly_a ly_ad y_ada _adam adams dams_ ams_c ms_co s_con _cons conso onsor nsort sort_ ort_s rt_sa t_sat _satu satur aturd turda urday rday_ day_1 ay_11 y_11t _11th 11th_ 1th_u th_ul h_ult _ult_ ult_m lt_mr t_mr_ _mr_j mr_jo r_jos _jose josep oseph seph_ eph_m ph_me h_mey _meye meyer eyer_ yer_h er_ha r_ham _hamp hamps ampst mpste pstea stead tead_ ead_w ad_wa d_was _was_ was_f as_fo s_fou _foun found ound_ und_d nd_de d_dea _dead dead_ ead_r ad_ro d_roa _road road_ oad_h ad_hi d_his _his_ his_h is_ho s_hor _hors horse orse_ rse_s se_st e_sta _stan stand tandi andin nding ding_ ing_h ng_hi g_him _him_ him_o im_oy m_oy_ _oy_s oy_sm y_smi _smit smith mith_ ith_r th_ru h_rus _rust rust_ ust_p st_po t_poc _pock pocke ocket cket_ ket_b et_bo t_boo _book book_ ook_l ok_lo k_los _lost lost_ ost_l st_lo t_los _lost lost_ ost_l st_la t_las _last last_ ast_w st_we t_wed _wedn wedne ednes dnesd nesda esday sday_ day_b ay_be y_bet _betw betwe etwee tween ween_ een_c en_cl n_clo _cloc clock lock_ ock_a ck_af k_aft _afte after ftern terno ernoo rnoon noon_ oon_e on_ei n_eit _eith eithe ither ther_ her_g er_gl r_glo _glob globe lobe_ obe_t be_ta e_tav _tave taver avern vern_ ern_p rn_pl n_pla _plai plain lains ains_ ins_r ns_ro s_roa _road road_ oad_l ad_le d_lea _lead leadi eadin ading ding_ ing_t ng_th g_the _then thenc hence ence_ nce_p ce_po e_por _port ports ortsm rtsmo tsmou smout mouth outh_ uth_n th_ne h_new _new_ new_r ew_re w_red _red_ red_m ed_mo d_mor _moro moroc orocc rocco occo_ cco_p co_po o_poc _pock pocke ocket cket_ ket_b et_bo t_boo _book book_ ook_c ok_co k_con _cont conta ontai ntain taini ainin ining ning_ ing_s ng_so g_som _some some_ ome_m me_mo e_mon _mone money oney_ ney_n ey_no y_not _note notes otes_ tes_h es_ha s_han _hand hand_ and_p nd_pa d_pay _paya payab ayabl yable able_ ble_s le_su e_sub _subs subsc ubscr bscri scrib cribe riber iber_ ber_a er_al r_als _also also_ lso_n so_ne o_new _new_ new_h ew_ha w_ham _hamp hamps ampsh mpshi pshir shire hire_ ire_f re_fi e_fir _fire fire_ ire_m re_ma e_mar _mari marin arine rine_ ine_c ne_ce e_cer _cert certi ertif rtifi tific ifica ficat icate cates ates_ tes_o es_ot s_oth _othe other ther_ her_p er_pa r_pap _pape paper apers pers_ ers_v rs_va s_val _valu valua aluab luabl uable able_ ble_n le_no e_non _none none_ one_b ne_bu e_but _but_ but_o ut_ow t_own _owne owner wner_ ner_w er_wh r_who _whoe whoev hoeve oever ever_ ver_s er_sh r_sha _shal shall hall_ all_f ll_fi l_fin _find find_ ind_s nd_sa d_sai _said said_ aid_p id_po d_poc _pock pocke ocket cket_ ket_b et_bo t_boo _book book_ ook_r ok_re k_re_ _re_t re_tu e_tur _turn turn_ urn_i rn_it n_its _its_ its_c ts_co s_con _cont conte onten ntent tents ents_ nts_w ts_wi s_wit _with witho ithou thout hout_ out_m ut_mo t_mon _mone money oney_ ney_s ey_sh y_sha _shal shall hall_ all_h ll_ha l_han _hand hands andso ndsom dsome somel omely mely_ ely_r ly_re y_rew _rewa rewar eward warde arded rded_ ded_t ed_th d_tha _than thank hanks anks_ nks_t ks_th s_the _thei their heir_ eir_h ir_hu r_hum _humb humbl umble mble_ ble_s le_se e_ser _serv serva ervan rvant vant_ ant_e nt_ed t_edw _edwa edwar dward ward_ ard_p rd_pa d_par _parr parry arry_ rry_l ry_le y_let _let_ let_f et_fi t_fir _fire firep irepr repro eproo proof roof_ oof_s of_st f_sto _stor store tore_ ore_l re_la e_lat _late latel ately tely_ ely_i ly_im y_imp _impr impro mprov prove roved oved_ ved_m ed_mr d_mr_ _mr_b mr_be r_ben _benj benja enjam njami jamin amin_ min_s in_sw n_swe _swet swett wett_ ett_m tt_mu t_mus _must must_ ust_a st_al t_all _allo allow llowe lowed owed_ wed_b ed_be d_bes _best best_ est_s st_st t_sta _stan stand tand_ and_b nd_bu d_bus _busi busin usine sines iness ness_ ess_e ss_ei s_eit _eith eithe ither ther_ her_e er_en r_eng _engl engli nglis glish lish_ ish_w sh_we h_wes _west west_ est_i st_in t_ind _indi india ndia_ dia_g ia_go a_goo _good goods oods_ ods_t ds_to s_tow _town town_ own_i wn_in n_inq _inqu inqui nquir quire uire_ ire_e re_ed e_edw _edwa edwar dward ward_ ard_p rd_pa d_par _parr parry arry_ rry_h ry_ha y_has _has_ has_l as_la s_lar _larg large arge_ rge_a ge_as e_ass _asso assor ssort sortm ortme rtmen tment ment_ ent_f nt_fa t_fas _fash fashi ashio shion hiona ionab onabl nable able_ ble_g le_go e_goo _good goods oods_ ods_s ds_sa s_sal _sale sale_ ale_c le_ch e_che _chea cheap heap_ eap_c ap_ca p_cas _cash cash_ ash_s sh_sh h_sho _shor short hort_ ort_c rt_cr t_cre _cred credi redit edit_ dit_j it_ju t_jul _july july_ uly_2 ly_28 y_28_ _28_s 28_sa 8_sal _sale sale_ ale_n le_ne e_new _new_ new_g ew_go w_gon _gond gondo ondol ndola dola_ ola_b la_bu a_bui _buil built uilt_ ilt_b lt_be t_bes _best best_ est_m st_ma t_mat _mate mater ateri teria erial rials ials_ als_e ls_ex s_exp _expe exper xperi perie erien rienc ience enced nced_ ced_w ed_wo d_wor _work workm orkma rkman kman_ man_f an_fo n_for _fort forty orty_ rty_f ty_fe y_fee _feet feet_ eet_c et_co t_cor _cor_ cor_n or_ne r_ner _ner_ ner_p er_pi r_pie _piec piece iece_ ece_f ce_fu e_fur _furt furth urthe rther ther_ her_p er_pa r_par _part parti artic rticu ticul icula cular ulars lars_ ars_e rs_en s_enq _enqu enqui nquir quire uire_ ire_m re_mi e_mic _mich micha ichae chael hael_ ael_w el_wi l_wig _wigg wiggi iggin ggin_ gin_n in_ne n_new _newm newma ewmar wmark marke arket rket_ ket_j et_ju t_jul _july july_ uly_2 ly_27 y_27t _27th 27th_ 7th_1 th_18 h_180 _1807 1807_ 807_c 07_ch 7_cha _chai chais haise'}]\n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['context'].fillna(\"\").astype(str).apply(lambda x: to_ngrams(x, n=5))\n",
    "\n",
    "docs = df[[\"docno\", \"text\"]].to_dict(\"records\")\n",
    "print(docs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85902d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuzzy_query created:\n",
      "   query_id                                           question       qid  \\\n",
      "0    test_1               How many lots did Thomas Peirce have    test_1   \n",
      "1   test_10  Who gave Hamilton the substance of what he had...   test_10   \n",
      "2  test_100  Who informs his FRIENDS and the PUBLIC that he...  test_100   \n",
      "\n",
      "                                               query  \n",
      "0  many_ any_l ny_lo y_lot _lots lots_ ots_d ts_d...  \n",
      "1  gave_ ave_h ve_ha e_ham _hami hamil amilt milt...  \n",
      "2  infor nform forms orms_ rms_h ms_hi s_his _his...  \n"
     ]
    }
   ],
   "source": [
    "fuzzy_query = queries_df.copy()\n",
    "fuzzy_query['query'] = fuzzy_query['query'].apply(lambda x: to_ngrams(x, n=5))\n",
    "\n",
    "# Sanity Check\n",
    "print(\"fuzzy_query created:\")\n",
    "print(fuzzy_query.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de7d994",
   "metadata": {},
   "source": [
    "Create the index again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "973f4684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing complete\n"
     ]
    }
   ],
   "source": [
    "INDEX_FUZZY_PATH = \"./indices/fuzzy_index_v2\"\n",
    "\n",
    "indexer_fuzzy = pt.index.IterDictIndexer(\n",
    "    INDEX_FUZZY_PATH,\n",
    "    meta={\"docno\": 50},\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Set properties to disable standard English processing\n",
    "indexer_fuzzy.setProperty(\"termpipelines\", \"\") \n",
    "indexer_fuzzy.setProperty(\"tokeniser\", \"WhitespaceTokeniser\") # Split only on the spaces we added\n",
    "\n",
    "indexref = indexer_fuzzy.index(docs)\n",
    "index_fuzzy = pt.IndexFactory.of(indexref)\n",
    "\n",
    "print(\"Indexing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d3faa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_fuzzy_5 = pt.terrier.Retriever(\n",
    "    index_fuzzy, \n",
    "    wmodel=\"BM25\", \n",
    "    properties={\"termpipelines\": \"\", \"tokeniser\": \"WhitespaceTokeniser\"}, # must match indexing\n",
    "    verbose=True # Shows a progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c7c80f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first 100 queries\n",
    "test_slice = 100\n",
    "test_queries = fuzzy_query[:test_slice]\n",
    "\n",
    "relevant_qids = test_queries['qid'].values\n",
    "filtered_qrels = qrels_df[qrels_df['qid'].isin(relevant_qids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03239483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TerrierRetr(BM25): 100%|██████████| 100/100 [00:12<00:00,  8.30q/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_5_results = bm25_fuzzy_5.transform(test_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c78bf3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R@1': 0.72, 'R@100': 0.96, 'AP': 0.7764373180530402}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "eval_metrics = pt.Evaluate(\n",
    "    bm25_5_results,\n",
    "    filtered_qrels,\n",
    "    metrics=[R@1, R@100, MAP]\n",
    ")\n",
    "\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a41f2b",
   "metadata": {},
   "source": [
    "# Fusion Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8cba6a",
   "metadata": {},
   "source": [
    "Now, let's try to fuse 4 and 5 grams together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9b0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 5-gram index from: ./indices/fuzzy_index_v2\n",
      "Loading 4-gram index from: ./indices/fuzzy_index_v1\n",
      "Running Fusion on existing indices...\n",
      "{'R@1': 0.69, 'R@100': 0.96, 'AP': 0.7489637691166716}\n"
     ]
    }
   ],
   "source": [
    "# Load the Existing Indices\n",
    "path_to_5g = \"./indices/fuzzy_index_v2\" # v2 is the 5-gram one\n",
    "path_to_4g = \"./indices/fuzzy_index_v1\" # v1 is the 4-gram one\n",
    "\n",
    "print(f\"Loading 5-gram index from: {path_to_5g}\")\n",
    "index_5g_loaded = pt.IndexFactory.of(path_to_5g)\n",
    "\n",
    "print(f\"Loading 4-gram index from: {path_to_4g}\")\n",
    "index_4g_loaded = pt.IndexFactory.of(path_to_4g)\n",
    "\n",
    "# Define Retrievers\n",
    "bm25_5g = pt.terrier.Retriever(\n",
    "    index_5g_loaded, \n",
    "    wmodel=\"BM25\",\n",
    "    controls={\"c\": 0.4, \"bm25.k_1\": 1.2},\n",
    "    properties={\"termpipelines\": \"\", \"tokeniser\": \"WhitespaceTokeniser\"}\n",
    ")\n",
    "\n",
    "bm25_4g = pt.terrier.Retriever(\n",
    "    index_4g_loaded, \n",
    "    wmodel=\"BM25\",\n",
    "    controls={\"c\": 0.4, \"bm25.k_1\": 1.2},\n",
    "    properties={\"termpipelines\": \"\", \"tokeniser\": \"WhitespaceTokeniser\"}\n",
    ")\n",
    "\n",
    "# Define the Translators\n",
    "def format_5g(row): return to_ngrams(row['question'], n=5)\n",
    "def format_4g(row): return to_ngrams(row['question'], n=4)\n",
    "\n",
    "# Create the Pipelines\n",
    "pipe_5g = pt.apply.query(format_5g) >> bm25_5g\n",
    "pipe_4g = pt.apply.query(format_4g) >> bm25_4g\n",
    "\n",
    "# Fuse & Run\n",
    "fusion_pipeline = (0.8 * pipe_5g) + (0.2 * pipe_4g)\n",
    "\n",
    "print(\"Running Fusion on existing indices...\")\n",
    "results = fusion_pipeline.transform(queries_df[:100])\n",
    "\n",
    "# Evaluate\n",
    "from pyterrier.measures import R, MAP\n",
    "relevant_qids = queries_df[:100]['qid'].values.astype(str)\n",
    "filtered_qrels = qrels_df[qrels_df['qid'].isin(relevant_qids)]\n",
    "\n",
    "eval_metrics = pt.Evaluate(\n",
    "    results,\n",
    "    filtered_qrels,\n",
    "    metrics=[R@1, R@100, MAP]\n",
    ")\n",
    "\n",
    "print(eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4dabc5",
   "metadata": {},
   "source": [
    "## RRF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b666dd",
   "metadata": {},
   "source": [
    "Let's try reciprocal rank fusion to see if it get's better results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdcdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier_alpha as pta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117fe54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R@1': 0.67, 'R@100': 0.94, 'AP': 0.7310782365821938}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This transformer merges multiple ranking results by computing the reciprocal rank of each document in each ranking, and summing them up. \n",
    "The reciprocal rank is computed as 1/(rank + k), where k is a constant. \n",
    "The resulting score is used to rank the documents.\n",
    "\"\"\"\n",
    "\n",
    "# Create the fusion pipeline using RRF\n",
    "rrf_pipeline = pta.fusion.RRFusion(\n",
    "    pipe_5g, \n",
    "    pipe_4g, \n",
    "    k=60\n",
    ")\n",
    "\n",
    "results_rrf = rrf_pipeline.transform(queries_df[:100])\n",
    "\n",
    "# Evaluate\n",
    "eval_metrics = pt.Evaluate(\n",
    "    results_rrf,\n",
    "    filtered_qrels,\n",
    "    metrics=[R@1, R@100, MAP]\n",
    ")\n",
    "print(eval_metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8107ba",
   "metadata": {},
   "source": [
    "We can also utilize the pt.Experiment method to compare our character n-gram representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb09e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           name       map  recip_rank   R@1  R@100  map +  map -  map p-value  \\\n",
      "0  4-Gram Fuzzy  0.717240    0.717240  0.64   0.92    NaN    NaN          NaN   \n",
      "1  5-Gram Fuzzy  0.754516    0.754516  0.70   0.96   23.0    6.0     0.040295   \n",
      "\n",
      "   recip_rank +  recip_rank -  recip_rank p-value  R@1 +  R@1 -  R@1 p-value  \\\n",
      "0           NaN           NaN                 NaN    NaN    NaN          NaN   \n",
      "1          23.0           6.0            0.040295    7.0    1.0     0.033199   \n",
      "\n",
      "   R@100 +  R@100 -  R@100 p-value  \n",
      "0      NaN      NaN            NaN  \n",
      "1      4.0      0.0       0.044935  \n"
     ]
    }
   ],
   "source": [
    "# Run the Experiment\n",
    "experiment = pt.Experiment(\n",
    "    [pipe_4g, pipe_5g],        # List of systems to compare\n",
    "    queries_df[:100],                 # The DATAFRAME with raw English queries\n",
    "    filtered_qrels,                    # The qrels\n",
    "    eval_metrics=[\"map\", \"recip_rank\", R@1, R@100],\n",
    "    names=[\"4-Gram Fuzzy\", \"5-Gram Fuzzy\"], \n",
    "    baseline=0                         # Compare the second model against the first (0-index)\n",
    ")\n",
    "\n",
    "print(experiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
